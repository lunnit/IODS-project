# Assignment 6. Analysis of longitudinal data

```{r}
#libraries 
library(dplyr)
library(tidyr)
library(lme4)
library(ggplot2)
library (ggpubr)

```

This week we are doing our analyses with two different data sets. The first, “RATS” concerns the weight of rats. The second data set, “BPRS”, deals with different treatments for psychiatric disorders. 

## Analyses with the RATS data

```{r}
#get the data and factor it 
RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", header = TRUE, sep = '\t')
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)
RATSL <- pivot_longer(RATS, cols=-c(ID,Group), names_to = "WD",values_to = "Weight")  %>%  mutate(Time = as.integer(substr(WD,3,4))) %>% arrange(Time)
```



```{r}
glimpse(RATSL)
summary(RATSL)
```

The data includes 16 rats divided into three groups that were given different diets. The rats were weighed approximately once a week over a 9-week period. 


```{r}
RATSL <- RATSL %>%
  group_by(Time) %>%
  mutate(std_W = (Weight - mean(Weight))/sd(Weight) ) %>%
  ungroup()

ggplot(RATSL, aes(x = Time, y = Weight, group = ID)) +
  geom_line(aes(linetype = Group, col = Group)) +
  scale_x_continuous(name = "Time (days)", breaks = seq(0, 60, 10)) +
  scale_y_continuous(name = "Observed weight (grams)") +
  theme(legend.position = "top")

ggplot(RATSL, aes(x = Time, y = std_W, group = ID)) +
  geom_line(aes(linetype = Group, col = Group)) +
  scale_x_continuous(name = "Time (days)", breaks = seq(0, 60, 10)) +
  scale_y_continuous(name = "Standardised weight") +
  theme(legend.position = "top")


```

According to, a graphical examination, there seems to be a quite big difference between group 1 and the other two groups. However, it seems like all of the rats in group 1 were smaller to begin with.  So, the effect might be due to their original size being smaller. The second plot, which presents standardised values,  implies this being the case. 


```{r}
RATSS <- RATSL %>%
  group_by(Group, Time) %>%
  summarise( mean = mean(Weight), se = sd(Weight) ) %>%
  ungroup()

#glimpse(RATSS)

ggplot(RATSS, aes(x = Time, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,4)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
  theme(legend.position = "right") +
  scale_y_continuous(name = "mean(weight) +/- se(weight)")

RATSLF <-   filter(RATSL, ID != 12)

RATSSF <- RATSLF %>%
  group_by(Group, Time) %>%
  summarise( mean = mean(Weight), se = sd(Weight) ) %>%
  ungroup()

ggplot(RATSSF, aes(x = Time, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,4)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
  theme(legend.position = "right") +
  scale_y_continuous(name = "mean(weight) +/- se(weight)")




```


The graph above shows the development of the rats’ weight during the experiment. In addition to the mean of the groups, there are error bars present. When it comes to groups 2 and 3, their error bars overlap quite much meaning there would be no difference between the groups. However, this is probably due to a single rat being an outlier. Dropping that rat from the data and drawing a new plot with filtered data shows a bit different picture. Now the error bars do not overlap at all. 



```{r}
RATSL64 <- RATSL %>%
  filter(Time > 1) %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()


# Draw a boxplot of the mean versus treatment
ggplot(RATSL64, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(weight), weeks 2-64")

RATSL64F <-   filter(RATSL64, mean < 550)

ggplot(RATSL64F, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(weight), weeks 2-64")



```

The boxplot graphs summarise the mean weights of the three groups in a single graph.  The outlier is even clearer in this graph and removing it shows us that the variation within the groups is rather small. The first week is taken off for these graphs as it is a baseline. 



```{r}
#t.test(mean ~ Group , data = RATSL64F, var.equal = TRUE)

t<-aov(mean ~ Group , data=RATSL64F)
t
summary(t)

RATSL64F2 <- RATSL64 %>%
  mutate(baseline = RATS$WD1)

# Fit the linear model with the mean as the response 
fit <- lm(mean ~ baseline +Group  , data = RATSL64F2)

fit
# Compute the analysis of variance table for the fitted model with anova()
anova(fit)


```

As there are three groups, I applied ANOVA to test if there is a difference between the mean weights of the groups. For the analysis, I used filtered data. ANOVA implies that there is a difference as the test is statistically significant.  

For linear regression, the baseline (week 1) is added back to the data as a new variable. This is done to control the original differences in the rats’ weights. Applying ANOVA to the results of a simple logistic regression shows us that the baseline (the original weight) affects the mean weight of the rats. However, diets do not seem to have an effect on the weights of different groups. 

The method used here is not the recommended way to deal with autocorrelated data. Linear regression still assumes the independence of the participants. The next part, on the other hand, applies a regression technique that takes into account the special nature of longitudinal data. 

## Analyses with the BPRS data

```{r}
#get the data and factor it 
BPRS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", sep  =" ", header = T)
BPRS$treatment <- factor(BPRS$treatment)
BPRS$subject <- factor(BPRS$subject)
BPRSL <-  pivot_longer(BPRS, cols=-c(treatment,subject),names_to = "weeks",values_to = "bprs") %>% arrange(weeks)
BPRSL <-  BPRSL %>% mutate(week = as.integer(substr(weeks,5,5)))

```


```{r}

ggplot(BPRSL, aes(x = week, y = bprs, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(BPRSL$bprs), max(BPRSL$bprs)))


BPRSL <- BPRSL %>%
  group_by(week) %>%
  mutate(stdbprs = (bprs - mean(bprs))/sd(bprs) ) %>%
  ungroup()


ggplot(BPRSL, aes(x = week, y = stdbprs, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_y_continuous(name = "stdbprs")

```


A graphical examination of the data does not give a clear picture of possible differences in the treatment groups.  The patients in both treatment groups do report having fewer symptoms at the end of the follow-up period. However, there seems to be some tracing effect i.e. participants who had more symptoms at the beginning also have more symptoms at the end. The second graph tries to deal with that by standardising the data. 


```{r}

# create a regression model BPRS_reg
BPRS_reg <- lm(bprs ~ week + treatment, data = BPRSL)

# print out a summary of the model
summary(BPRS_reg)

```

Fitting a simple linear regression tells us that time might affect the number of symptoms the participants have. Treatment, on the other hand, does not seem to have an effect. However, the method does not take into account autocorrelation which is unavoidable in data that follows the same participants. Next, we try to fit a random intercept model which is a method that  can handle longitudinal data. 

```{r}
# Create a random intercept model
BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRSL, REML = FALSE)

# Print the summary of the model
summary(BPRS_ref)

```
A random intercept model fits the same slope to all groups with varying intercepts. Therefore a graph of the predicted regression line shows a set of parallel lines.

Fixed effects tell us the coefficients of the model. In this case,  the variable week seems to have a negative effect on symptoms ( -2.27) and treatment2 has a slightly positive effect. In other words, time reduced symptoms but treatment2 did not (in comparison to treatment1). 



```{r}

# create a random intercept and random slope model
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRSL, REML = FALSE)

# print a summary of the model

summary(BPRS_ref1)


# perform an ANOVA test on the two models
anova(BPRS_ref1, BPRS_ref)

```


A random intercept and random slope model lets the slope vary in the addition to the intercept. Therefore, a graph of the predicted regression line would show lines for the groups. The lines would not need to be parallel or have the same intercept anymore. 


ANOVA is used to test which model fits the data better. BIC is one value used to evaluate the fit of a model. The lower the value is, the better. Now, our first model had a BIC value of 2768.1 and the second had a value of 2772.6. It seems that the first, simpler model fits the data better this time.  


```{r}
# create a random intercept and random slope model with the interaction
BPRS_ref2 <- lmer(bprs ~ week + treatment + week*treatment + (week | subject), data = BPRSL, REML = FALSE)

# print a summary of the model
summary(BPRS_ref2)

# perform an ANOVA test on the two models
anova(BPRS_ref2, BPRS_ref1)

anova(BPRS_ref, BPRS_ref2, BPRS_ref1)

```

Lastly, we do a model that checks if there is an interaction between time (week) and treatment. After taking the interaction into account, treatment has a negative coefficient (-2.29) which is rather similar to the week’s coefficient (-2.62). Now both seem to reduce the symptoms. 

To be honest, I am not sure what to think about the comparison between all three models. The BIC value of the first model is the lowest but only the second model has statistical significance. 

```{r}

Fitted <- fitted(BPRS_ref2)
BPRSL$fitted <- Fitted

ggplot(BPRSL, aes(x = week, y = stdbprs, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_y_continuous(name = "stdbprs")


ggplot(BPRSL, aes(x = week, y = fitted, linetype = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_y_continuous(name = "stdbprs")


```


Plotting the results of the last model in comparison to observed values shows us that both treatments seem to work. Both groups have negative coefficients. In treatment group 1, the coefficients might be a bit larger and therefore the treatment a bit more effective. However, the difference is tiny if even there. 
